# README - GraphRAG + Neo4j çŸ¥è­˜æª¢ç´¢ç³»çµ± (ç”± ChatGPT-5 å”åŠ©è£½ä½œ)

æœ¬å°ˆæ¡ˆç´€éŒ„äº† **å¦‚ä½•å¾ 0 é–‹å§‹å»ºç«‹ GraphRAG ç³»çµ±ï¼Œä¸¦æ•´åˆ Neo4j åœ–è³‡æ–™åº«èˆ‡ Ollama æœ¬åœ°æ¨¡å‹**ï¼Œå®Œæ•´æµç¨‹åŒ…å«ï¼š
- å®‰è£èˆ‡ç’°å¢ƒè¨­å®š
- GraphRAG å°å…¥èˆ‡ç´¢å¼•æµç¨‹
- Neo4j é€£æ¥èˆ‡åœ–è³‡æ–™å¯«å…¥
- æ¸¬è©¦ç¨‹å¼ç¢¼ (äº’å‹•å¼å•ç­”)
- æ¯æ®µç¨‹å¼ç¢¼çš„è©³ç´°è§£é‡‹

---

## ğŸ› ï¸ 1. ç’°å¢ƒå®‰è£

```bash
# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv .venv
.venv\Scripts\Activate.ps1   # Windows å•Ÿç”¨è™›æ“¬ç’°å¢ƒ

# å‡ç´š pip
pip install --upgrade pip

# å®‰è£ GraphRAG
pip install graphrag

# å®‰è£ Chroma, Neo4j Driver, Jieba
pip install chromadb neo4j jieba requests
```

---

## âš™ï¸ 2. è¨­å®š `settings.yaml`

åœ¨ `GraphRAG/settings.yaml` å…§è¨­å®šï¼š

```yaml
models:
  default_chat_model:
    type: openai_chat
    auth_type: api_key
    api_key: ollama
    api_base: http://127.0.0.1:11434/v1
    model: llama3.1:8b
    model_supports_json: false
    concurrent_requests: 2
    async_mode: threaded
    retry_strategy: native
    max_retries: 5

  default_embedding_model:
    type: openai_embedding
    auth_type: api_key
    api_key: ollama
    api_base: http://127.0.0.1:11434/v1
    model: bge-m3
    model_supports_json: false
    concurrent_requests: 2
    async_mode: threaded
    retry_strategy: native
    max_retries: 5

input:
  storage:
    type: file
    base_dir: "input"
  file_type: text

chunks:
  size: 1200
  overlap: 100

output:
  type: file
  base_dir: "output"

cache:
  type: file
  base_dir: "cache"

reporting:
  type: file
  base_dir: "logs"

vector_store:
  default_vector_store:
    type: lancedb
    db_uri: output/lancedb
    container_name: default
    overwrite: True
```

---

## ğŸ“‚ 3. è³‡æ–™æº–å‚™

åœ¨ `GraphRAG/input/` æ”¾å…¥åŸå§‹è³‡æ–™ï¼Œä¾‹å¦‚ï¼š

```
GraphRAG/input/ä¸­é†«è¨ºç™‚é…æ–¹.txt
```

---

## âš¡ 4. å»ºç«‹ç´¢å¼•

```bash
graphrag index --root .
```

åŸ·è¡Œå¾Œæœƒä¾åºè·‘ï¼š
1. è®€å–æ–‡ä»¶
2. åˆ‡å‰² chunks
3. æŠ½å–å¯¦é«”é—œä¿‚
4. ç”Ÿæˆç¤¾ç¾¤å ±å‘Š
5. å»ºç«‹å‘é‡è³‡æ–™åº«

---

## ğŸ”— 5. Neo4j å®‰è£èˆ‡è¨­å®š

å®‰è£ Neo4j Desktop æˆ– Neo4j Serverï¼Œä¸¦è¨­å®šï¼š
- é€£ç·š URI: `bolt://localhost:7687`
- å¸³è™Ÿ: `neo4j`
- å¯†ç¢¼: `12345Lkk` (å¯è‡ªè¡Œä¿®æ”¹)

---

## ğŸ¤– 6. æ¸¬è©¦ç¨‹å¼ç¢¼ (test.py)

ä»¥ä¸‹ç¨‹å¼ç¢¼æœƒï¼š
1. è®€å– `input` å…§çš„ txt
2. åˆ†æ®µä¸¦å‘é‡åŒ–
3. å¯«å…¥ **Chroma** èˆ‡ **Neo4j**
4. æä¾›äº’å‹•å¼å•ç­”

```python
# -*- coding: utf-8 -*-
import os
os.environ["CHROMADB_ANON_TELEMETRY"] = "False"

import re
import uuid
import requests
import subprocess
from collections import Counter

import chromadb
import jieba
from neo4j import GraphDatabase

# ====== åŸºæœ¬è¨­å®š ======
GRAPHRAG_ROOT = r"D:\ç¶²é \RAG\GraphRAG"
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "12345Lkk"

def get_neo_driver():
    return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

STOPWORDS = set(["çš„","äº†","èˆ‡","åŠ","è€Œ","ä¸¦","å…¶","ä¹‹","åœ¨","å’Œ","æˆ–","ä»¥åŠ","å°æ–¼","å¦‚æœ","å¯èƒ½","éœ€è¦"])

# Step 1: è®€å–æ–‡æœ¬ä¸¦åˆ‡åˆ†
def file_chunk_list():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(base_dir, "input", "ä¸­é†«è¨ºç™‚é…æ–¹.txt")
    with open(file_path, encoding="utf-8", mode="r") as fp:
        raw = fp.read()
    text = raw.replace("\r\n", "\n").strip()
    chunks = [c.strip() for c in re.split(r"\n{2,}", text) if c.strip()]
    return chunks

# Step 2: Embedding API
def ollama_embedding_by_api(text):
    res = requests.post("http://127.0.0.1:11434/api/embeddings",
        json={"model": "bge-m3", "prompt": text}, timeout=120)
    return res.json()['embedding']

# Step 3: LLM ç”Ÿæˆ API
def ollama_generate_by_api(prompt):
    response = requests.post("http://127.0.0.1:11434/api/generate",
        json={"model": "llama3.1:8b", "prompt": prompt, "stream": False, "temperature": 0.1}, timeout=600)
    return response.json().get('response', '')

# Step 4: åˆå§‹åŒ–è³‡æ–™ (Chroma + Neo4j)
def initial():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    db_path = os.path.join(base_dir, "db", "chroma_demo")
    client = chromadb.PersistentClient(path=db_path)
    collection = client.get_or_create_collection(name="collection_v2")

    documents = file_chunk_list()
    ids = [f"chunk_{i:04d}" for i in range(len(documents))]

    embeddings, ok_docs, ok_ids = [], [], []
    for cid, doc in zip(ids, documents):
        try:
            emb = ollama_embedding_by_api(doc)
            embeddings.append(emb)
            ok_docs.append(doc)
            ok_ids.append(cid)
        except Exception as e:
            print(f"[WARN] embedding å¤±æ•—: {cid} -> {e}")

    if ok_docs:
        collection.add(ids=ok_ids, documents=ok_docs, embeddings=embeddings)

    print(f"[INGEST DONE] å…± {len(ok_docs)} ç­†å¯«å…¥")

# Step 5: å•ç­”
def interactive():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    db_path = os.path.join(base_dir, "db", "chroma_demo")
    client = chromadb.PersistentClient(path=db_path)
    collection = client.get_or_create_collection(name="collection_v2")

    while True:
        qs = input("è¼¸å…¥å•é¡Œ (æˆ–è¼¸å…¥ exit é›¢é–‹): ")
        if qs.lower() == "exit":
            break

        qs_embedding = ollama_embedding_by_api(qs)
        res = collection.query(query_embeddings=[qs_embedding], query_texts=[qs], n_results=8)
        docs = res["documents"][0] if res and res.get("documents") else []
        context = "\n".join(docs)

        prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ä¸­é†«åŠ©ç†ã€‚åƒ…æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”ï¼š

[ä½¿ç”¨è€…å•é¡Œ]
{qs}

[åƒè€ƒè³‡æ–™]
{context}

è«‹å›ç­”ï¼š
"""
        ans = ollama_generate_by_api(prompt)
        print("=== å›ç­” ===")
        print(ans)
        print("============\n")

if __name__ == "__main__":
    initial()
    interactive()
```

---

## ğŸ§© 7. ç¨‹å¼ç¢¼è§£é‡‹

- `file_chunk_list()` â†’ åˆ‡å‰² txt æˆ chunks
- `ollama_embedding_by_api()` â†’ ç”¨ Ollama ç”¢ç”Ÿå‘é‡
- `ollama_generate_by_api()` â†’ ç”¨ Ollama LLM ç”Ÿæˆå›ç­”
- `initial()` â†’ æŠŠè³‡æ–™å¯«å…¥ **Chroma** èˆ‡ **Neo4j**
- `interactive()` â†’ å•Ÿå‹•äº’å‹•å¼å•ç­”ï¼Œæ¯æ¬¡è¼¸å…¥å•é¡Œéƒ½æœƒæª¢ç´¢è³‡æ–™ä¸¦å›ç­”

---

## ğŸ¯ 8. ä½¿ç”¨æ–¹å¼

```bash
python test.py
```

åŸ·è¡Œå¾Œæœƒå‡ºç¾ï¼š

```
è¼¸å…¥å•é¡Œ (æˆ–è¼¸å…¥ exit é›¢é–‹):
```

è¼¸å…¥ä»»ä½•å•é¡Œï¼Œç³»çµ±å°±æœƒä¾æ“šè³‡æ–™åº«çµ¦å‡ºæœ€ä½³å›ç­”ã€‚

---

## âœ… 9. æ³¨æ„äº‹é …

- æœ¬ç³»çµ±åƒ…ä¾› **æ•™è‚²ç”¨é€”**ï¼Œä¸æ˜¯æ­£å¼é†«ç™‚å»ºè­°ã€‚
- è‹¥ç”¨æ–¼å…¶ä»–é ˜åŸŸï¼Œè«‹æ›´æ› `input/` ä¸‹çš„åŸå§‹è³‡æ–™ã€‚
- éœ€å…ˆå•Ÿå‹• **Neo4j** èˆ‡ **Ollama ä¼ºæœå™¨**ã€‚

---

å®Œæˆï¼ ğŸ‰  
